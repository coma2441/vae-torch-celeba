# VAE CelebA - Clean & Organized

A Variational Autoencoder (VAE) implementation for CelebA face generation with comprehensive training visualizations and smart inference capabilities.

## ğŸ—‚ï¸ Project Structure

```
vae-torch-celeba/
â”œâ”€â”€ vae.py              # VAE model architecture
â”œâ”€â”€ train.py            # Training script with visualization checkpoints
â”œâ”€â”€ train_vae.sh        # Automated training script with MPS fallback
â”œâ”€â”€ inference.py        # Smart inference with auto model detection
â”œâ”€â”€ utils.py            # Utility functions
â”œâ”€â”€ data/               # CelebA dataset
â”‚   â””â”€â”€ celeba/
â”‚       â””â”€â”€ img_align_celeba/    # Face images (*.jpg)
â”œâ”€â”€ models/             # Trained model files
â”‚   â”œâ”€â”€ vae_quick_trained.pth
â”‚   â”œâ”€â”€ vae_trained_from_scratch.pth
â”‚   â””â”€â”€ vae_model_20.pth
â””â”€â”€ outputs/            # Generated images and training progress
    â”œâ”€â”€ generated_random.jpg
    â”œâ”€â”€ latent_interpolation.jpg
    â”œâ”€â”€ reconstruction_test.jpg
    â””â”€â”€ training_progress/       # Visualization checkpoints
        â”œâ”€â”€ epoch_001_*.jpg      # Initial results
        â”œâ”€â”€ epoch_010_*.jpg      # 10-epoch checkpoint  
        â”œâ”€â”€ epoch_020_*.jpg      # 20-epoch checkpoint
        â””â”€â”€ epoch_final_*.jpg    # Final results
```

## ğŸš€ Quick Start

### 1. Automated Training (Recommended)
```bash
# Run complete training with visualization checkpoints
./train_vae.sh
```

### 2. Manual Training
```bash
# Set MPS fallback for Apple Silicon compatibility
export PYTORCH_ENABLE_MPS_FALLBACK=1

# Train from scratch (creates models/vae_trained_from_scratch.pth)
python train.py
```

### 3. Generate Images
```bash
# Smart inference - automatically uses best available model
python inference.py
```

## ğŸ“‹ Features

### ğŸ§  **Smart Model Management**
- **Auto Model Detection**: Automatically finds and uses the best available model
- **Model Priority**: Quick trained â†’ Full trained â†’ Original pretrained
- **Organized Storage**: All models saved in `models/` directory

### ğŸ¨ **Comprehensive Visualizations**
- **Training Checkpoints**: Visual progress at epochs 1, 10, 20, and final
- **Three Visualization Types**:
  - **Random Generation**: 16 diverse generated faces
  - **Latent Interpolation**: Smooth morphing between faces  
  - **Reconstruction**: Original vs reconstructed comparisons
- **Progress Tracking**: Watch quality improve over training epochs

### ğŸš€ **GPU Acceleration** 
- **MPS Support**: Optimized for Apple Silicon (M1/M2/M3)
- **CUDA Support**: Works with NVIDIA GPUs
- **Automatic Fallback**: CPU operations when GPU doesn't support specific ops
- **Smart Device Detection**: Automatically uses best available device

### ğŸ“¸ **Multiple Generation Modes**
- **Random Face Generation**: Create diverse new faces
- **Latent Space Interpolation**: Smooth transitions between faces
- **Image Reconstruction**: Test model's understanding of real faces

## ğŸ¨ Generated Outputs

### **Inference Results** (`outputs/`)
1. **Random Generation** (`generated_random.jpg`): 16 randomly generated faces
2. **Latent Interpolation** (`latent_interpolation.jpg`): Smooth morphing between faces
3. **Reconstruction** (`reconstruction_test.jpg`): Original vs reconstructed comparison

### **Training Progress** (`outputs/training_progress/`)
Each checkpoint includes three visualization types:
- `epoch_XXX_random_generation.jpg` - Generated faces at that epoch
- `epoch_XXX_interpolation.jpg` - Latent space interpolations
- `epoch_XXX_reconstruction.jpg` - Reconstruction quality test

## ğŸ”§ Configuration

- **Image Size**: 150x150 pixels
- **Latent Dimensions**: 128
- **Architecture**: Convolutional encoder-decoder with batch normalization
- **Training**: 20 epochs, batch size 64, Adam optimizer
- **Loss Function**: MSE reconstruction + KL divergence (Î²=0.00025)
- **Dataset**: 10,000 CelebA images (8,000 train + 2,000 test)

## ğŸ“Š Model Priority

The inference script automatically selects models in this order:
1. `models/vae_quick_trained.pth` (if available)
2. `models/vae_trained_from_scratch.pth` (if available)  
3. `models/vae_model_20.pth` (original pretrained)

## ğŸ› ï¸ Requirements

- PyTorch with MPS/CUDA support
- torchvision  
- Pillow
- CelebA dataset in `data/celeba/img_align_celeba/`

## ğŸ“ˆ Training Visualization Schedule

- **Epoch 1**: Initial checkpoint (see early learning)
- **Epoch 10**: Quality improvement checkpoint  
- **Epoch 20**: Final epoch checkpoint
- **Final**: Comprehensive final visualization

## ğŸ¯ Benefits

- **ğŸ‘ï¸ Visual Progress Tracking**: See how faces improve over time
- **ğŸ› Early Problem Detection**: Spot issues like mode collapse quickly  
- **ğŸ“ˆ Training Insights**: Understand what the model learns when
- **ğŸ¨ Beautiful Results**: Create a training progress story
- **ğŸš€ Easy Automation**: One-click training with `./train_vae.sh`

## ğŸ’¡ Usage Tips

- Use `./train_vae.sh` for hassle-free training with all optimizations
- Check `outputs/training_progress/` during training to monitor quality
- The script handles MPS fallback automatically for Apple Silicon compatibility
- Training takes ~20-30 minutes on Apple Silicon GPUs

Enjoy creating beautiful AI-generated faces! ğŸ­âœ¨
* `genpics.py`: creates a panel of original image + 7 reconstructed ones.

Running a trained model on a CPU is fine. 

Training on a CPU is possible, but slow: âš¡ğŸ‘‰ GPU.
